* FlowCL
A graph-oriented, optionally-typed, optionally-verifiable language built over Common Lisp.

*WARNING: FlowCL is currently in beta! Both the code itself and the paradigm it aims to crystallize in code are subject to change.*
+ In addition, the project structure is in flux, and it is currently published primarly to get external overviews, criticism, and recommendations on relevant materials (e.g. similar projects or writing on similar concepts). This notification will be removed from the README when enough features have been implemented to provide an idea of how v1 of the API should be designed.

The Flow language is a long-term project on my part, attempting to extend Common Lisp (and hopefully other runtimes in the future) with the ability to interactively build programs around the flow of information.

There are a few core concepts which guide the design and implementation of Flow:
- Graph-oriented: Flow is intended to [TBC]
- ...

FlowCL is intended to integrate with its host languages, allowing integration into existing codebases.

** Design principles
Some key principles of the FlowCL project:

- *Compatibility*: FlowCL strives to be compatible with code, libraries, and paradigms used by the framework's users.

  Functionality will be encapsulated as much as possible (e.g. within function/procedure/object definitions), and external endpoints can ideally be added directly to your code with no change in operation or design (save, hopefully, for increased ease-of-coding and potentially also performance).

  FlowCL will also attempt to use libraries such as "trivial-extensible-sequences" to make drop-in replacement even easier, by enabling compatibility with code that was designed for non-FlowCL structures.

- *Scalability*: FlowCL is meant to be a basis upon which small and large projects are built. As such, it should allow composition of its elements into larger structures without significant compromises. Ease of use will be a particular target to maintain as code or data structures are composed into larger structures.

  Another target of this goal is reliability. In a mature state, FlowCL will match the reliability of production level code, and be usable in the same.

  Ideally, FlowCL code should also provide efficiency boosts to the user. In some cases this will be outweighed by other factors, such as ease of use. However, we aim to identify opportunities for our code to optimize not only based on its own structure, but also based on information gleaned from how it is being used in a larger context, allowing us to automate a significant portion of the optimization work that would normally be done manually by programmers. This is the same approach used by software such as TensorFlow, to allow users to easly build large systems without unnecessarily large hardware costs or loss of performance.

- *Ease of use*: FlowCL aims for developers to easily use it.

  In part, this is a longer-term goal to implement documentation and tutorials to ease comprehension and adoption of the project. In the shorter term, this aspect will be fulfilled primarly through clear, understandable naming and documentation within the code.

  This goal also applies to the design of the framework itself. Endpoints intended for external use should be designed to easily integrate with each other and external code, such as through the creation of utilities for creating or manipulating FlowCL constructs (note that compatibility with native constructs would be a very nice feature for such utilities). In addition, where possible internal functionality should be constructed in such a way as to allow users to easily modify the system, without constantly breaking things or having to deal with excessive or obtuse interdependencies.

- *Extensibility*: One of the strengths of CL is its strong culture of backward-compatibility. However, sometimes this can also impede the ability to modify and improve a project.

  There are two main approaches to solve this issue. Firstly, we will design symbols intended as external endpoints to be as independent as possible from the internal implementations. This should allow us more freedom to improve the FlowCL project and the code of its users without any action on their part.

  Secondly, we will not limit ourselves to publishing a single package. Once the FlowCL project has matured enough to have a stable API, we will suffix package names with the "v0.01" convention. The latest stable sub-version will be aliased to its version, and the latest stable version will be aliased to un-suffixed "default" package names (i.e. the package "flow-cl-v0.01" will be aliased to "flow-cl-v0", which will be aliased to "flow-cl"). Many projects implement this process via Github branches, but our approach allows both active developers and users to track package versions without dealing with branches or commit history, making it significantly easier for package users to contribute improvements.
  + NOTE: "Major version" package names (e.g. "v1") are intended to be retained indefinitely. However, the minor versions underlying them (e.g. "v0.01", "v0.02", etc) are very likely to be discarded, and are mainly for development purposes. Once FlowCL is mature enough for the above system to be implemented, we *strongly recommend either pinning code to a major version or just using the default packages*.

** Installation
Place this repository somewhere ASDF or Quicklisp can find it as a local project, and then use `(ql:quickload :flow-cl)` (or `(asdf:load-system :flow-cl)`, which quicklisp wraps in its quickload feature).

** Usage

** Progress and Roadmap

Future plans are currently vague, but currently involve the following points:
- [-] Develop a prototype for node/graph computation
  - [-] Develop an extensible node abstraction
    - [X] Figure out the basic conceptual structure of the core node class
      - Currently thinking about making this just a directed graph of inputs/outputs with a ~value~ slot for node data/metadata
    - [ ] Implement a decent prototype of the core node class
    - [-] Figure out extension points
    - [-] Figure out how to define behavior for specific node subclasses
    - [-] Figure out how to contain and execute computations in a node
    - [-] Figure out how to traverse nodes by their connections
      - [X] Implement simple traversals (e.g. BFS, DFS)
      - [ ] Verify that the traversal API is extensible and allows full expression of the power of the underlying node-network systems
    - [ ] Figure out how to execute a network of nodes
      - [ ] Figure out reasonably-efficient execution in the DAG context
      - [ ] Figure out how to deal with loops
      - [ ] Figure out how to reduce code-graphs based on runtime information
        - Shouldn't compromise other features like traversal or looping
    - [ ] Figure out how macros work in node networks
      - [ ] Figure out how to structure macroexpansion time vs runtime
        - Should I make a distinction and do multiple expansion passes before the execution pass? Integrate macroexpansion into the type propagation pass, maybe?
      - [ ] Figure out if it's possible to ergonomically denote the scope of a macro, and if so how
      - [ ] Figure out how macros interact if their range of influence overlaps
    - [ ] Develop a compilation framework for networks of nodes
      - [ ] Figure out how to find patterns in graphs and replace them with more efficient alternatives before/outside-of runtime
        - Preferably this allows both noticing patterns before runtime and just simplifying things based on runtime values...
          - Would the latter (simplifying code based on runtime values) require the full dependent typing system?
      - [ ] Figure out how to denote compilation behavior of individual nodes in relation to their contexts in a graph
        - [ ] Figure out what kinds of behavior and relevant aspects might be needed
          - Cost estimates? How to represent these?
          - (optional) Probability estimates for code-paths / a subset of possible value-types at a point?
            - With the right planning algorithms, this would allow things like reasonable auto-optimization of multi-device computations
        - [ ] Figure out a way to implement compilation and aspect-tracking in an extensible manner
        - [ ] Figure out how to actually denote the compilation behavior
        - [ ] Figure out how to deal with different behavior of different nodes/node-classes
      - [ ] Figure out how to choose between multiple possible compilation directions
  - [ ] Develop an extensible object/class abstraction for graphs
    - A graph is intended to be a collection of nodes with aggregate behavior.
    - [ ] Figure out how to collect nodes in a graph and refer to a graph's components
      - [ ] Figure out how to store the nodes
      - [ ] Figure out how to access a graph's components with reasonable efficiency
      - [ ] Figure out how to execute a graph
      - [ ] Figure out how to compile a graph
        - [ ] Figure out how to denote compilation characteristics of graphs
        - [ ] Figure out how graph compilation interacts with e.g. one graph being contained by another
    - [ ] Figure out graph-specific operations
      - [ ] Comparison between graphs
        - Should probably have a way to determine if graphs have the same structure, and if so call them equal
      - [ ] Copying graphs
      - [ ] Including one graph in another
        - [ ] How do we do this without sharing the same graph object across instances?
        - [ ] How do we update the included graphs if the original changes?
        - [ ] Compilation
    - [ ] Develop a way for graph programs to modify themselves, i.e. graph macros
      - [ ] Figure out how this differs from just networks of nodes
      - [ ] Figure out the semantics of execution times and graph compilation
      - [ ] Figure out how to formalize the concept of modifiers on existing nodes/graphs/graph-segments
  - [-] Develop some proof-of-concepts for the usefulness of the node abstraction in normal CL code
    - [-] Reactive programming
      - [X] Prototype exists
      - [ ] Update after the node semantics are tied down
    - [-] Syntax for making node programs in CL code
      - [X] Prototype exists
      - [ ] Update after the node semantics are tied down
    - [ ] Compiling program dataflow
      - Possible implementation: implement a simple from-scratch neural network and auto-parallelize and auto-optimize
- [ ] Develop a framework for execution contexts
  - [ ] Tracking the current execution environment as a graph is traversed
    - [ ] Storing the execution environment
    - [ ] Representing computations that read/write to the execution environment
    - [ ] Efficiency
      - Resources:
        - [ ] Glicol - A graph-oriented language developed in Rust: https://webaudioconf.com/_data/papers/pdf/2021/2021_8.pdf
          - Glicol uses a clock to avoid recomputation if the value of something is already known at the current clock time (essentially meaning that none of the dependencies have changed since the last computation). A similar system could be used in Flow, since with both language environment and external environment being first-class objects we have the runtime managing all possible inputs to a node
    - [ ] Figuring out the semantics to denote "universes" in the graph
      - [ ] Syntax for this?
      - [ ] How will this actually work?
        - [ ] Look at Lean and similar languages for inspiration here?
        - [ ] Look at delimited continuations?
          - These seem to be implementable as the special-case where a universe is a copy of its entire parental context
          - Resources:
            - [-] Handling delimited continuations with dependent types: https://dl.acm.org/doi/10.1145/3236764
        - [ ] Look at natural language?
          - Resources:
            - [ ] Context-linked grammar: https://www.sciencedirect.com/science/article/abs/pii/S0388000114000515
        - [ ] Look to see if anything as broad as what I'm imagining already exists
    - [ ] Inheritance between environments
      - [ ] Figure out limits on which universes can inherit from which others
        - E.g. based on position in the graph
      - [ ] Dealing with inherited values and their updates
      - [ ] Dealing with access syntax/semantics
      - [ ] Multiple inheritance
        - Most likely this will end up creating a DAG of environments
      - [ ] Representing the outside world (i.e. the host language and external environment) in the universe context
        - Likely will be the parent of the runtime's other universes, with the Flow runtime creating a child universe for itself from which all other universes can inherit
        - [ ] Dealing with external events
          - Examples: filesystem, network, etc
        - [ ] Dealing with interop
    - [ ] Tracking interactions between environment and runtime code
      - [ ] Tracking which parts of the environment are affected by specific code
        - May need to work out the full type system for this...
        - This falls into tracking the purity of code (all interactions with the environment are read-only)
    - [ ] Moving execution between different places on the graph
      - How do I maintain the execution-context continuations in this case?
      - How do we get unwind-protect like functionality, for cases where
  - [ ] Parallel execution of graphs
    - This would need to be worked out along with the execution contexts, to avoid the latter obstructing the former and requiring hacky workarounds.
- [ ] Develop an optional dependent typing framework for graphs
  - [ ] Study dynamic typing
    - [ ] Figure out the semantics of type representation and manipulation
    - [ ] Figure out the semantics for type tracking
      - [ ] Figure out how these types will behave and be organized
        - [ ] Figure out the basics of how this variant of types work
        - [ ] Figure out how types will interact with the other language features
    - [ ] Figure out if I can get away with just making other types warn unless required by the programmer, and make the entire system dynamic with warnings that way
      - Resources:
        - [ ] Dynamic Typing with Dependent Types: https://www.cs.princeton.edu/~dpw/papers/DTDT-tr.pdf
  - [ ] Study HM typing
    - [ ] Figure out the semantics of type representation and manipulation
    - [ ] Figure out the semantics for type tracking
      - [ ] Figure out how these types will behave and be organized
        - [ ] Figure out the basics of how this variant of types work
          - [ ] Look at Haskell as a potential case-study
        - [ ] Figure out how types will interact with the other language features
    - [ ] Figure out how this typing can be done optionally
    - [ ] Figure out if we need this or can skip directly to fully-provable types
  - [ ] Study dependent typing and proof-based languages
    - [ ] Figure out the semantics of type representation and manipulation
    - [ ] Figure out the semantics for type tracking
      - [ ] Figure out how these types will behave and be organized
        - [ ] Figure out the basics of how this variant of types work
        - [ ] Figure out how types will interact with the other language features
          - [ ] Figure out how dependent types will interact with unvierses
            - Resources:
              - [-] Handling delimited continuations with dependent types: https://dl.acm.org/doi/10.1145/3236764
                - This talks about splitting into pure and impure cases so that the pure case can allow more in-depth dependent typing. It seems the same approach could be taken with universes, where interactions with a segment of a universe that is a parent of the targeted universe means said targeted universe can only be legally shared and called outside said parent if dependent typing is being forced in this context.
          - [ ] Figure out how dependent types will interact with macros
            - Can I just let it loosen instead, save for inlining cases? So you execute macros at compile time, and blocks get compiled when defined rather than at the call site? That way you can always get a full expansion of the code graph by propagating type information through it and expanding macros as you reach a node in their scope; and in inlining cases the inline itself acts as a macro, so you can treat it the same way.
            - Resources:
              - Dependent type systems as macros: https://arxiv.org/abs/2107.01295
                - A macro framework for _implementing_ dependent type systems, rather than a way to use macros within one, but nonetheless useful for implementation reasons and potentially relevant here as well
      - [ ] Figure out how to deal with Girard's Paradox
        - Resources:
          - [-] Functional programming in Lean - Universes: https://lean-lang.org/functional_programming_in_lean/functor-applicative-monad/universes.html
            - It seems that Lean takes the approach of an implicit infinite regression of universes for these situations (e.g. for the type of ~Type~). Could I implement the universe graph to have implicit transitions, to allow this approach?
      - [ ] Figure out how degree of provability interacts with efficiency and usability
        - [ ] Look at Coq as a potential case-study
        - [ ] Look at Lean as a potential case-study
    - [ ] Figure out how this typing can be done optionally
    - Resources:
      - [ ] Simply Easy - An implementation of a dependently typed lambda calculus: http://strictlypositive.org/Easy.pdf
      - [ ] Defining Types in Shen: https://bluishcoder.co.nz/2019/10/03/defining-types-in-shen.html
        - Shen allows toggling the type system (which presumably involves toggling an environment variable); this format could be usable for controlling the level of contstraint from the type system in Flow
      - [ ] Shen Logic Lab (a proof assistant system for Shen): https://shenlanguage.org/logiclab.html
        - This is a proof assistant built inside Shen; depending on the details of the description videos, I might be able to do the same for actually implementing formal verification of Flow programs / program contracts
  - [ ] Figure out the interfaces between the different type-systems
  - [ ] Figure out the user-API for this
    - [ ] How do users specify the type system to use?
    - [ ] How do users manipulate each type of type?
    - [ ] How do users make assertions for each type system, and how do those assertions influence compilation?
    - [ ] How can users extend the above type system for different implementaitons and/or extensions of the above concepts?
      - It would be best if I could find a way to make this something that can be added on later, to speed up the development of a language prototype.
  - [ ] Figure out the semantics for interactions bet
  - [ ] Implement the framework for atoms, functions, macros, etc
  - [ ] Implement the framework for types
  - [ ] Implement the framework for universes
- [-] Develop the user interface for this language
  - Needs to be done in tandem with the other steps
  - [-] Syntax?
    - [ ] Look into Lisps
    - [ ] Look into ML
    - [-] Look into Ithkuil
      - https://www.ithkuil.net/
      - Words have a base to which modifiers and parameters are applied.
      - Both here and in general in natural language, sentences seem to be the points where you escape local contexts/parentheses and return to the grounding of the current universe
  - [ ] Representation of data/programs?
  - [ ] Restrictions on user behavior and their bypasses?
- [ ] Implement sample libraries
  - Goals:
    - Demonstrate how to write pure Flow code
    - Demonstrate how to write external code and near-seamlessly interop with it
  - [ ] Interop with pure CL
  - [ ] Efficient arithmetic / linear algebra
  - [ ] Pure-Flow Machine learning framework
  - [ ] Library for interop with an external Python process through the REPL and filesystem
- [ ] Narrow down a core kernel for better compatibility
  - [ ] Move as much functionality as possible into the language syntax itself
  - [ ] Operationalize the semantics for functionality that can't be bootstrapped
  - [ ] Make a sample implementation in another language

- Complete the lazy programming sub-framework?
  - This may not be worth it, compared to just starting anew
  - This may be better served in a separate library rather than as a part of the FlowCL implementation.

  - Improving the efficiency.

    Time-wise, the lazy-vector structure matches native code by applying functions to its internal vector cache, providing reasonable time efficiency.

    However, the space-efficiency of the laziness system is rather bad; for extremely large inputs, I've sometimes run into heap failures without explicit garbage-collection.
    We need to find ways to reduce the space taken by lazy structures
    + lazy-cons (which is also currently the backbone of lazy-vector) is a significant offender here; reimplementing it to use an internal list cache like lazy-vector, and perhaps using the cdr to store tails when lazy-consing multiple lazy sequences, might work to resolve this issue, and could also allow reusing the lazy-vector code which permits sharing of evaluation where possible.

      However, this has the issue that it forces the user to only use structures which cache their results. This is not necessarily a good thing, considering that they may be using lazy sequences to process data too large to actively keep in memory. Further thought is required here.

    + lazy-vector should benefit from explicitly using a function as its generator rather than shelling out to lazy-cons objects. lazy-vec may not even need to be reworked; if we can figure out another function template for lazy-vectors *not* derived from lazy-conses, we will likely not need to change the lazy-vector so much that lazy-vec can't just be tweaked a little to store and retrieve the input lazy-cons in the right place.

    + NOTE: If lazy-vector stops being a subclass of lazy-cons, we will need to rework the class architecture. I think a good approach would be to make a "lazy-sequence" object defining the shared slots and specializing most of the generic methods, with only the lowest-level methods directly specializing on different lazy sequences

    We also might want to optimize their garbage collection (perhaps using weak-pointers for reuse of defunct objects that haven't been garbage collected?).

  - Improving the feature-set

    Currently, the only features implemented are the core thunk class, and lazy-cons and lazy-vector as replacement sequences for lists and vectors.

    One direction for progress is incorporating streams into the library, allowing them to be wrapped as lazy-sequences. We may need to restrict this functionality considering that you can't go backwards in a stream, but our lazy stream object should at least allow the composition of mapping, filtration, etc that lazy sequences currently permit.

    + Perhaps this could be done via documentation suggesting restrictions on usage to avoid making calls that are supposed to refer to the same items in the stream, and/or creating a macro for stream interaction and which inherently contains such restrictions.

      The macro approach seems particularly interesting. If the user can specify a set of sequences which are meant to receive the data from the stream, then the macro could internally create a cache object which only retains those aspects of the stream which are necessary given the current state of the various sequences. Including any non-lazy sequences would force full reading and caching of the stream, but lazy-sequences would wait on cache reads and stream-reads (to extend the cache) based on which elements were forced to evaluate.

      Once no objects were waiting on a value of the macro's internal cache, that value could be discarded (possibly using the :offset value with periodic copy-seq commands, if using a lazy-vector?). This would allow a rolling track on only those values which are necessary, without the user needing to manually program such caching.

      However, this method requires either lazy sequences which discard data automatically (e.g. the current implementation of lazy-cons, if we make the old heads space-efficient enough to be feasible for production); or, preferably, a method to update the list of receiving sequences, so that the user can decide when to discard old data. Perhaps just allowing setf on the defined sequences would be enough for this.
      + Incidentally, having this feature in the core macro would make it much easier to implement a convenience macro on top of it, which tracks the size of the receiving sequences and automatically replaces them with copies (if the user is confident that only the current datapoint and/or a preset amount of history will be relevant).

    We also need to explicitly develop the design to optionally permit interaction without preservation of values (either directly in the code or through making it easy to discard cached information). This is necessary for processing of extremely large values (as mentioned in the musing on stream wrappers above), but seems at odds with the goal of maintaining performance (unless calculating the step function is *extremely* computation-heavy); further thought is required here.

  - Improving the integration.

    The lazy-programming framework is currently placed *literally just in the flow-cl package*. The first priority here is moving it to its own package and figuring out how the package architecture is going to work.

    After that, I need to figure out how users will interact with this system. Obviously one mode is to use the enclosed lazy sequences as drop-in sequence objects compatible with Common Lisp sequence functions (assuming your implementation is compatible with trivial-extensible-sequences, or you use the appropriate fallback code).

    Another mode would be to make specific use-cases for lazy-sequences (such as wrapping streams) and writing drop-in macros to implement that specific feature.

    Ideally, another mode will be added using a macro to implement a DSL for lazy programming. The result of code written in that DSL would be the output of the form, allowing for integration into normal CL code. However, *this is a minor goal*, and takes a backseat to working on other subsystems of the overall FlowCL framework.

- ...

** Author

+ Swapneil Singh

** Copyright

Copyright (c) 2023 Swapneil Singh

** License

Licensed under the MIT License.
